{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim\n",
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "%matplotlib  inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rouge import Rouge \n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "% time\n",
    "with open('./data_pointer_example.txt', 'r', encoding='UTF-8') as f:\n",
    "    stories = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embedding = np.load('Word2vec_pointer.npz')['E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.strftime('%Y-%b-%d-%H-%M-%S', time.gmtime())\n",
    "\n",
    "save_model_path = os.path.join('won', ts)\n",
    "os.makedirs('./'+save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "\n",
    "  def __init__(self, vocab_file, max_size):\n",
    "    self._word_to_id = {}\n",
    "    self._id_to_word = {}\n",
    "    self._count = 0 # keeps track of total number of words in the Vocab\n",
    "\n",
    "    # [UNK], [PAD], [START] and [STOP] get the ids 0,1,2,3.\n",
    "    for w in [UNKNOWN_TOKEN, PAD_TOKEN, START_DECODING, STOP_DECODING]:\n",
    "      self._word_to_id[w] = self._count\n",
    "      self._id_to_word[self._count] = w\n",
    "      self._count += 1\n",
    "\n",
    "    # Read the vocab file and add words up to max_size\n",
    "    with open(vocab_file, 'r', encoding='utf-8') as vocab_f:\n",
    "      for line in vocab_f:\n",
    "        pieces = line.split()\n",
    "        if len(pieces) != 2:\n",
    "          print ('Warning: incorrectly formatted line in vocabulary file: %s\\n' % line)\n",
    "          continue\n",
    "        w = pieces[0]\n",
    "        if w in [SENTENCE_START, SENTENCE_END, UNKNOWN_TOKEN, PAD_TOKEN, START_DECODING, STOP_DECODING]:\n",
    "          raise Exception('<s>, </s>, [UNK], [PAD], [START] and [STOP] shouldn\\'t be in the vocab file, but %s is' % w)\n",
    "        if w in self._word_to_id:\n",
    "          raise Exception('Duplicated word in vocabulary file: %s' % w)\n",
    "        self._word_to_id[w] = self._count\n",
    "        self._id_to_word[self._count] = w\n",
    "        self._count += 1\n",
    "        if max_size != 0 and self._count >= max_size:\n",
    "          print (\"max_size of vocab was specified as %i; we now have %i words. Stopping reading.\" % (max_size, self._count))\n",
    "          break\n",
    "\n",
    "    print (\"Finished constructing vocabulary of %i total words. Last word added: %s\" % (self._count, self._id_to_word[self._count-1]))\n",
    "\n",
    "  def word2id(self, word):\n",
    "    if word not in self._word_to_id:\n",
    "      return self._word_to_id[UNKNOWN_TOKEN]\n",
    "    return self._word_to_id[word]\n",
    "\n",
    "  def id2word(self, word_id):\n",
    "    if word_id not in self._id_to_word:\n",
    "      raise ValueError('Id not found in vocab: %d' % word_id)\n",
    "    return self._id_to_word[word_id]\n",
    "\n",
    "  def size(self):\n",
    "    return self._count\n",
    "\n",
    "  def write_metadata(self, fpath):\n",
    "    print (\"Writing word embedding metadata file to %s...\" % (fpath))\n",
    "    with open(fpath, \"w\") as f:\n",
    "      fieldnames = ['word']\n",
    "      writer = csv.DictWriter(f, delimiter=\"\\t\", fieldnames=fieldnames)\n",
    "      for i in xrange(self.size()):\n",
    "        writer.writerow({\"word\": self._id_to_word[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <s> and </s> are used in the data files to segment the abstracts into sentences. They don't receive vocab ids.\n",
    "SENTENCE_START = '<s>'\n",
    "SENTENCE_END = '</s>'\n",
    "\n",
    "PAD_TOKEN = '[PAD]' # This has a vocab id, which is used to pad the encoder input, decoder input and target sequence\n",
    "UNKNOWN_TOKEN = '[UNK]' # This has a vocab id, which is used to represent out-of-vocabulary words\n",
    "START_DECODING = '[START]' # This has a vocab id, which is used at the start of every decoder input sequence\n",
    "STOP_DECODING = '[STOP]' # This has a vocab id, which is used at the end of untruncated target sequences\n",
    "\n",
    "# Note: none of <s>, </s>, [PAD], [UNK], [START], [STOP] should appear in the vocab file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: incorrectly formatted line in vocabulary file: 0800 555 111 356\n",
      "\n",
      "\n",
      "Warning: incorrectly formatted line in vocabulary file: 1800 333 000 139\n",
      "\n",
      "\n",
      "Warning: incorrectly formatted line in vocabulary file: 2 1/2 124\n",
      "\n",
      "\n",
      "Warning: incorrectly formatted line in vocabulary file: 3 1/2 86\n",
      "\n",
      "\n",
      "max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.\n",
      "Finished constructing vocabulary of 50000 total words. Last word added: long-delayed\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab('./vocab', 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example(object):\n",
    "\n",
    "  def __init__(self, article, abstract_sentences, vocab):\n",
    "    # Get ids of special tokens\n",
    "    start_decoding = vocab.word2id(START_DECODING)\n",
    "    stop_decoding = vocab.word2id(STOP_DECODING)\n",
    "\n",
    "    # Process the article\n",
    "    article_words = article.split()\n",
    "    if len(article_words) > 200:\n",
    "      article_words = article_words[:200]\n",
    "    self.enc_len = len(article_words) # store the length after truncation but before padding\n",
    "    self.enc_input = [vocab.word2id(w) for w in article_words] # list of word ids; OOVs are represented by the id for UNK token\n",
    "\n",
    "    # Process the abstract\n",
    "    abstract = ' '.join(abstract_sentences) # string\n",
    "    abstract_words = abstract.split() # list of strings\n",
    "    abs_ids = [vocab.word2id(w) for w in abstract_words] # list of word ids; OOVs are represented by the id for UNK token\n",
    "\n",
    "    # Get the decoder input sequence and target sequence\n",
    "    self.dec_input, self.target = self.get_dec_inp_targ_seqs(abs_ids, 20, start_decoding, stop_decoding)\n",
    "    self.dec_len = len(self.dec_input)\n",
    "\n",
    "    # If using pointer-generator mode, we need to store some extra info\n",
    "    if True:\n",
    "      # Store a version of the enc_input where in-article OOVs are represented by their temporary OOV id; also store the in-article OOVs words themselves\n",
    "      self.enc_input_extend_vocab, self.article_oovs = article2ids(article_words, vocab)\n",
    "\n",
    "      # Get a verison of the reference summary where in-article OOVs are represented by their temporary article OOV id\n",
    "      abs_ids_extend_vocab = abstract2ids(abstract_words, vocab, self.article_oovs)\n",
    "\n",
    "      # Overwrite decoder target sequence so it uses the temp article OOV ids\n",
    "      _, self.target = self.get_dec_inp_targ_seqs(abs_ids_extend_vocab, 20, start_decoding, stop_decoding)\n",
    "\n",
    "    # Store the original strings\n",
    "    self.original_article = article\n",
    "    self.original_abstract = abstract\n",
    "    self.original_abstract_sents = abstract_sentences\n",
    "\n",
    "\n",
    "  def get_dec_inp_targ_seqs(self, sequence, max_len, start_id, stop_id):\n",
    "    inp = [start_id] + sequence[:]\n",
    "    target = sequence[:]\n",
    "    if len(inp) > max_len: # truncate\n",
    "      inp = inp[:max_len]\n",
    "      target = target[:max_len] # no end_token\n",
    "    else: # no truncation\n",
    "      target.append(stop_id) # end token\n",
    "    assert len(inp) == len(target)\n",
    "    return inp, target\n",
    "\n",
    "\n",
    "  def pad_decoder_inp_targ(self, max_len, pad_id):\n",
    "    while len(self.dec_input) < max_len:\n",
    "      self.dec_input.append(pad_id)\n",
    "    while len(self.target) < max_len:\n",
    "      self.target.append(pad_id)\n",
    "\n",
    "\n",
    "  def pad_encoder_input(self, max_len, pad_id):\n",
    "    while len(self.enc_input) < max_len:\n",
    "      self.enc_input.append(pad_id)\n",
    "    if True:\n",
    "      while len(self.enc_input_extend_vocab) < max_len:\n",
    "        self.enc_input_extend_vocab.append(pad_id)\n",
    "        \n",
    "def article2ids(article_words, vocab):\n",
    "  ids = []\n",
    "  oovs = []\n",
    "  unk_id = vocab.word2id(UNKNOWN_TOKEN)\n",
    "  for w in article_words:\n",
    "    i = vocab.word2id(w)\n",
    "    if i == unk_id: # If w is OOV\n",
    "      if w not in oovs: # Add to list of OOVs\n",
    "        oovs.append(w)\n",
    "      oov_num = oovs.index(w) # This is 0 for the first article OOV, 1 for the second article OOV...\n",
    "      ids.append(vocab.size() + oov_num) # This is e.g. 50000 for the first article OOV, 50001 for the second...\n",
    "    else:\n",
    "      ids.append(i)\n",
    "  return ids, oovs\n",
    "\n",
    "\n",
    "def abstract2ids(abstract_words, vocab, article_oovs):\n",
    "  ids = []\n",
    "  unk_id = vocab.word2id(UNKNOWN_TOKEN)\n",
    "  for w in abstract_words:\n",
    "    i = vocab.word2id(w)\n",
    "    if i == unk_id: # If w is an OOV word\n",
    "        #print(abstract_words)\n",
    "        ids.append(i) \n",
    "#       if w in article_oovs: # If w is an in-article OOV\n",
    "#         vocab_idx = vocab.size() + article_oovs.index(w) # Map to its temporary article OOV number\n",
    "#         ids.append(vocab_idx)\n",
    "#       else: # If w is an out-of-article OOV\n",
    "#         ids.append(unk_id) # Map to the UNK token id\n",
    "    else:\n",
    "        ids.append(i)\n",
    "  return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/288 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/288 [00:00<01:14,  3.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_000.bin 598\n",
      "./chunked/train_*.bin ./chunked\\train_000.bin 611\n",
      "./chunked/train_*.bin ./chunked\\train_000.bin 676\n",
      "./chunked/train_*.bin ./chunked\\train_000.bin 687\n",
      "./chunked/train_*.bin ./chunked\\train_000.bin 986\n",
      "./chunked/train_*.bin ./chunked\\train_001.bin 276\n",
      "./chunked/train_*.bin ./chunked\\train_001.bin 339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 2/288 [00:00<01:15,  3.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_001.bin 561\n",
      "./chunked/train_*.bin ./chunked\\train_001.bin 640\n",
      "./chunked/train_*.bin ./chunked\\train_001.bin 825\n",
      "./chunked/train_*.bin ./chunked\\train_001.bin 903\n",
      "./chunked/train_*.bin ./chunked\\train_002.bin 44\n",
      "./chunked/train_*.bin ./chunked\\train_002.bin 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 3/288 [00:00<01:14,  3.84it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_002.bin 727\n",
      "./chunked/train_*.bin ./chunked\\train_002.bin 941\n",
      "./chunked/train_*.bin ./chunked\\train_002.bin 956\n",
      "./chunked/train_*.bin ./chunked\\train_003.bin 56\n",
      "./chunked/train_*.bin ./chunked\\train_003.bin 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▏         | 4/288 [00:01<01:14,  3.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_003.bin 978\n",
      "./chunked/train_*.bin ./chunked\\train_004.bin 192\n",
      "./chunked/train_*.bin ./chunked\\train_004.bin 345\n",
      "./chunked/train_*.bin ./chunked\\train_004.bin 358\n",
      "./chunked/train_*.bin ./chunked\\train_004.bin 409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 5/288 [00:01<01:15,  3.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_004.bin 866\n",
      "./chunked/train_*.bin ./chunked\\train_004.bin 930\n",
      "./chunked/train_*.bin ./chunked\\train_005.bin 110\n",
      "./chunked/train_*.bin ./chunked\\train_005.bin 228\n",
      "./chunked/train_*.bin ./chunked\\train_005.bin 402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 6/288 [00:01<01:15,  3.73it/s]\u001b[A\n",
      "  2%|▏         | 7/288 [00:01<01:15,  3.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_006.bin 429\n",
      "./chunked/train_*.bin ./chunked\\train_006.bin 556\n",
      "./chunked/train_*.bin ./chunked\\train_006.bin 722\n",
      "./chunked/train_*.bin ./chunked\\train_006.bin 962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 8/288 [00:02<01:14,  3.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_007.bin 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 9/288 [00:02<01:23,  3.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_008.bin 753\n",
      "./chunked/train_*.bin ./chunked\\train_008.bin 770\n",
      "./chunked/train_*.bin ./chunked\\train_009.bin 347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 10/288 [00:02<01:21,  3.39it/s]\u001b[A\n",
      "  4%|▍         | 11/288 [00:03<01:20,  3.42it/s]\u001b[A\n",
      "  4%|▍         | 12/288 [00:03<01:19,  3.46it/s]\u001b[A\n",
      "  5%|▍         | 13/288 [00:03<01:18,  3.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_013.bin 161\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 562\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 563\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 564\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 565\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 566\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 567\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 568\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 569\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 570\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 571\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 572\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 573\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 14/288 [00:03<01:18,  3.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_013.bin 936\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 937\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 938\n",
      "./chunked/train_*.bin ./chunked\\train_013.bin 998\n",
      "./chunked/train_*.bin ./chunked\\train_014.bin 332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 15/288 [00:04<01:17,  3.53it/s]\u001b[A\n",
      "  6%|▌         | 16/288 [00:04<01:16,  3.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_015.bin 313\n",
      "./chunked/train_*.bin ./chunked\\train_015.bin 314\n",
      "./chunked/train_*.bin ./chunked\\train_015.bin 419\n",
      "./chunked/train_*.bin ./chunked\\train_015.bin 420\n",
      "./chunked/train_*.bin ./chunked\\train_015.bin 428\n",
      "./chunked/train_*.bin ./chunked\\train_015.bin 501\n",
      "./chunked/train_*.bin ./chunked\\train_015.bin 526\n",
      "./chunked/train_*.bin ./chunked\\train_015.bin 898\n",
      "./chunked/train_*.bin ./chunked\\train_015.bin 903\n",
      "./chunked/train_*.bin ./chunked\\train_016.bin 108\n",
      "./chunked/train_*.bin ./chunked\\train_016.bin 111\n",
      "./chunked/train_*.bin ./chunked\\train_016.bin 113\n",
      "./chunked/train_*.bin ./chunked\\train_016.bin 114\n",
      "./chunked/train_*.bin ./chunked\\train_016.bin 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 17/288 [00:04<01:16,  3.56it/s]\u001b[A\n",
      "  6%|▋         | 18/288 [00:05<01:15,  3.58it/s]\u001b[A\n",
      "  7%|▋         | 19/288 [00:05<01:14,  3.60it/s]\u001b[A\n",
      "  7%|▋         | 20/288 [00:05<01:14,  3.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_019.bin 413\n",
      "./chunked/train_*.bin ./chunked\\train_020.bin 28\n",
      "./chunked/train_*.bin ./chunked\\train_020.bin 29\n",
      "./chunked/train_*.bin ./chunked\\train_020.bin 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 21/288 [00:05<01:13,  3.61it/s]\u001b[A\n",
      "  8%|▊         | 22/288 [00:06<01:13,  3.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_021.bin 622\n",
      "./chunked/train_*.bin ./chunked\\train_021.bin 958\n",
      "./chunked/train_*.bin ./chunked\\train_022.bin 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 23/288 [00:06<01:13,  3.62it/s]\u001b[A\n",
      "  8%|▊         | 24/288 [00:06<01:12,  3.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_023.bin 376\n",
      "./chunked/train_*.bin ./chunked\\train_024.bin 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▊         | 25/288 [00:06<01:12,  3.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_024.bin 314\n",
      "./chunked/train_*.bin ./chunked\\train_024.bin 350\n",
      "./chunked/train_*.bin ./chunked\\train_024.bin 363\n",
      "./chunked/train_*.bin ./chunked\\train_024.bin 395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 26/288 [00:07<01:12,  3.63it/s]\u001b[A\n",
      "  9%|▉         | 27/288 [00:07<01:11,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_026.bin 300\n",
      "./chunked/train_*.bin ./chunked\\train_027.bin 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 28/288 [00:07<01:11,  3.64it/s]\u001b[A\n",
      " 10%|█         | 29/288 [00:07<01:11,  3.64it/s]\u001b[A\n",
      " 10%|█         | 30/288 [00:08<01:10,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_029.bin 611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 31/288 [00:08<01:10,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_030.bin 677\n",
      "./chunked/train_*.bin ./chunked\\train_030.bin 773\n",
      "./chunked/train_*.bin ./chunked\\train_030.bin 838\n",
      "./chunked/train_*.bin ./chunked\\train_031.bin 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 32/288 [00:08<01:10,  3.65it/s]\u001b[A\n",
      " 11%|█▏        | 33/288 [00:09<01:09,  3.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_032.bin 753\n",
      "./chunked/train_*.bin ./chunked\\train_033.bin 415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 34/288 [00:09<01:09,  3.65it/s]\u001b[A\n",
      " 12%|█▏        | 35/288 [00:09<01:09,  3.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_034.bin 726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▎        | 36/288 [00:09<01:08,  3.65it/s]\u001b[A\n",
      " 13%|█▎        | 37/288 [00:10<01:08,  3.65it/s]\u001b[A\n",
      " 13%|█▎        | 38/288 [00:10<01:08,  3.65it/s]\u001b[A\n",
      " 14%|█▎        | 39/288 [00:10<01:08,  3.65it/s]\u001b[A\n",
      " 14%|█▍        | 40/288 [00:10<01:07,  3.65it/s]\u001b[A\n",
      " 14%|█▍        | 41/288 [00:11<01:07,  3.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_040.bin 501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▍        | 42/288 [00:11<01:07,  3.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_041.bin 440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▍        | 43/288 [00:11<01:07,  3.65it/s]\u001b[A\n",
      " 15%|█▌        | 44/288 [00:12<01:06,  3.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_043.bin 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 45/288 [00:12<01:06,  3.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_045.bin 40\n",
      "./chunked/train_*.bin ./chunked\\train_045.bin 369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 46/288 [00:12<01:06,  3.65it/s]\u001b[A\n",
      " 16%|█▋        | 47/288 [00:12<01:05,  3.65it/s]\u001b[A\n",
      " 17%|█▋        | 48/288 [00:13<01:05,  3.66it/s]\u001b[A\n",
      " 17%|█▋        | 49/288 [00:13<01:05,  3.65it/s]\u001b[A\n",
      " 17%|█▋        | 50/288 [00:13<01:05,  3.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_049.bin 937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 51/288 [00:13<01:05,  3.65it/s]\u001b[A\n",
      " 18%|█▊        | 52/288 [00:14<01:04,  3.65it/s]\u001b[A\n",
      " 18%|█▊        | 53/288 [00:14<01:04,  3.64it/s]\u001b[A\n",
      " 19%|█▉        | 54/288 [00:14<01:04,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_053.bin 760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 55/288 [00:15<01:03,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_054.bin 642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 56/288 [00:15<01:03,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_055.bin 890\n",
      "./chunked/train_*.bin ./chunked\\train_056.bin 591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|█▉        | 57/288 [00:15<01:03,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_056.bin 676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 58/288 [00:15<01:03,  3.64it/s]\u001b[A\n",
      " 20%|██        | 59/288 [00:16<01:02,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_058.bin 341\n",
      "./chunked/train_*.bin ./chunked\\train_058.bin 447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 60/288 [00:16<01:02,  3.64it/s]\u001b[A\n",
      " 21%|██        | 61/288 [00:16<01:02,  3.65it/s]\u001b[A\n",
      " 22%|██▏       | 62/288 [00:17<01:01,  3.65it/s]\u001b[A\n",
      " 22%|██▏       | 63/288 [00:17<01:01,  3.65it/s]\u001b[A\n",
      " 22%|██▏       | 64/288 [00:17<01:01,  3.64it/s]\u001b[A\n",
      " 23%|██▎       | 65/288 [00:17<01:01,  3.63it/s]\u001b[A\n",
      " 23%|██▎       | 66/288 [00:18<01:01,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_065.bin 483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██▎       | 67/288 [00:18<01:00,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_067.bin 114\n",
      "./chunked/train_*.bin ./chunked\\train_067.bin 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 68/288 [00:18<01:00,  3.64it/s]\u001b[A\n",
      " 24%|██▍       | 69/288 [00:18<01:00,  3.64it/s]\u001b[A\n",
      " 24%|██▍       | 70/288 [00:19<00:59,  3.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_069.bin 903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▍       | 71/288 [00:19<00:59,  3.64it/s]\u001b[A\n",
      " 25%|██▌       | 72/288 [00:19<00:59,  3.64it/s]\u001b[A\n",
      " 25%|██▌       | 73/288 [00:20<01:01,  3.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_072.bin 920\n",
      "./chunked/train_*.bin ./chunked\\train_072.bin 942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 74/288 [00:21<01:01,  3.50it/s]\u001b[A\n",
      " 26%|██▌       | 75/288 [00:21<01:00,  3.51it/s]\u001b[A\n",
      " 26%|██▋       | 76/288 [00:21<01:00,  3.50it/s]\u001b[A\n",
      " 27%|██▋       | 77/288 [00:21<01:00,  3.50it/s]\u001b[A\n",
      " 27%|██▋       | 78/288 [00:22<00:59,  3.51it/s]\u001b[A\n",
      " 27%|██▋       | 79/288 [00:22<00:59,  3.51it/s]\u001b[A\n",
      " 28%|██▊       | 80/288 [00:22<00:59,  3.51it/s]\u001b[A\n",
      " 28%|██▊       | 81/288 [00:23<00:58,  3.51it/s]\u001b[A\n",
      " 28%|██▊       | 82/288 [00:23<00:58,  3.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_081.bin 686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 83/288 [00:23<00:58,  3.51it/s]\u001b[A\n",
      " 29%|██▉       | 84/288 [00:23<00:58,  3.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin ./chunked\\train_083.bin 574\n",
      "./chunked/train_*.bin ./chunked\\train_083.bin 924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|██▉       | 85/288 [00:24<00:57,  3.52it/s]\u001b[A\n",
      " 30%|██▉       | 86/288 [00:24<00:57,  3.52it/s]\u001b[A\n",
      " 30%|███       | 87/288 [00:24<00:57,  3.52it/s]\u001b[A\n",
      " 31%|███       | 88/288 [00:24<00:56,  3.52it/s]\u001b[A\n",
      " 31%|███       | 89/288 [00:25<00:56,  3.52it/s]\u001b[A\n",
      " 31%|███▏      | 90/288 [00:25<00:56,  3.53it/s]\u001b[A\n",
      " 32%|███▏      | 91/288 [00:25<00:55,  3.53it/s]\u001b[A\n",
      " 32%|███▏      | 92/288 [00:26<00:55,  3.53it/s]\u001b[A\n",
      " 32%|███▏      | 93/288 [00:26<00:55,  3.53it/s]\u001b[A\n",
      " 33%|███▎      | 94/288 [00:26<00:54,  3.53it/s]\u001b[A\n",
      " 33%|███▎      | 95/288 [00:26<00:54,  3.53it/s]\u001b[A\n",
      " 33%|███▎      | 96/288 [00:27<00:54,  3.53it/s]\u001b[A\n",
      " 34%|███▎      | 97/288 [00:27<00:54,  3.54it/s]\u001b[A\n",
      " 34%|███▍      | 98/288 [00:27<00:53,  3.53it/s]\u001b[A\n",
      " 34%|███▍      | 99/288 [00:28<00:53,  3.54it/s]\u001b[A\n",
      " 35%|███▍      | 100/288 [00:28<00:53,  3.54it/s]\u001b[A\n",
      " 35%|███▌      | 101/288 [00:28<00:52,  3.54it/s]\u001b[A\n",
      " 35%|███▌      | 102/288 [00:28<00:52,  3.54it/s]\u001b[A\n",
      " 36%|███▌      | 103/288 [00:29<00:52,  3.54it/s]\u001b[A\n",
      " 36%|███▌      | 104/288 [00:29<00:51,  3.54it/s]\u001b[A\n",
      " 36%|███▋      | 105/288 [00:29<00:51,  3.54it/s]\u001b[A\n",
      " 37%|███▋      | 106/288 [00:29<00:51,  3.54it/s]\u001b[A\n",
      " 37%|███▋      | 107/288 [00:30<00:51,  3.55it/s]\u001b[A\n",
      " 38%|███▊      | 108/288 [00:30<00:50,  3.55it/s]\u001b[A\n",
      " 38%|███▊      | 109/288 [00:30<00:50,  3.55it/s]\u001b[A\n",
      " 38%|███▊      | 110/288 [00:31<00:50,  3.55it/s]\u001b[A\n",
      " 39%|███▊      | 111/288 [00:31<00:49,  3.55it/s]\u001b[A\n",
      " 39%|███▉      | 112/288 [00:31<00:49,  3.55it/s]\u001b[A\n",
      " 39%|███▉      | 113/288 [00:31<00:49,  3.55it/s]\u001b[A\n",
      " 40%|███▉      | 114/288 [00:32<00:48,  3.56it/s]\u001b[A\n",
      " 40%|███▉      | 115/288 [00:32<00:48,  3.56it/s]\u001b[A\n",
      " 40%|████      | 116/288 [00:32<00:48,  3.56it/s]\u001b[A\n",
      " 41%|████      | 117/288 [00:32<00:48,  3.56it/s]\u001b[A\n",
      " 41%|████      | 118/288 [00:33<00:47,  3.56it/s]\u001b[A\n",
      " 41%|████▏     | 119/288 [00:33<00:47,  3.56it/s]\u001b[A\n",
      " 42%|████▏     | 120/288 [00:33<00:47,  3.56it/s]\u001b[A\n",
      " 42%|████▏     | 121/288 [00:33<00:46,  3.56it/s]\u001b[A\n",
      " 42%|████▏     | 122/288 [00:34<00:46,  3.57it/s]\u001b[A\n",
      " 43%|████▎     | 123/288 [00:34<00:46,  3.57it/s]\u001b[A\n",
      " 43%|████▎     | 124/288 [00:34<00:45,  3.57it/s]\u001b[A\n",
      " 43%|████▎     | 125/288 [00:35<00:45,  3.57it/s]\u001b[A\n",
      " 44%|████▍     | 126/288 [00:35<00:45,  3.57it/s]\u001b[A\n",
      " 44%|████▍     | 127/288 [00:35<00:45,  3.57it/s]\u001b[A\n",
      " 44%|████▍     | 128/288 [00:35<00:44,  3.57it/s]\u001b[A\n",
      " 45%|████▍     | 129/288 [00:36<00:44,  3.57it/s]\u001b[A\n",
      " 45%|████▌     | 130/288 [00:36<00:44,  3.58it/s]\u001b[A\n",
      " 45%|████▌     | 131/288 [00:36<00:43,  3.58it/s]\u001b[A\n",
      " 46%|████▌     | 132/288 [00:36<00:43,  3.58it/s]\u001b[A\n",
      " 46%|████▌     | 133/288 [00:37<00:43,  3.58it/s]\u001b[A\n",
      " 47%|████▋     | 134/288 [00:37<00:43,  3.58it/s]\u001b[A\n",
      " 47%|████▋     | 135/288 [00:37<00:42,  3.58it/s]\u001b[A\n",
      " 47%|████▋     | 136/288 [00:37<00:42,  3.58it/s]\u001b[A\n",
      " 48%|████▊     | 137/288 [00:38<00:42,  3.58it/s]\u001b[A\n",
      " 48%|████▊     | 138/288 [00:38<00:41,  3.58it/s]\u001b[A\n",
      " 48%|████▊     | 139/288 [00:38<00:41,  3.58it/s]\u001b[A\n",
      " 49%|████▊     | 140/288 [00:39<00:41,  3.58it/s]\u001b[A\n",
      " 49%|████▉     | 141/288 [00:39<00:40,  3.59it/s]\u001b[A\n",
      " 49%|████▉     | 142/288 [00:39<00:40,  3.59it/s]\u001b[A\n",
      " 50%|████▉     | 143/288 [00:39<00:40,  3.59it/s]\u001b[A\n",
      " 50%|█████     | 144/288 [00:40<00:40,  3.59it/s]\u001b[A\n",
      " 50%|█████     | 145/288 [00:40<00:39,  3.59it/s]\u001b[A\n",
      " 51%|█████     | 146/288 [00:40<00:39,  3.59it/s]\u001b[A\n",
      " 51%|█████     | 147/288 [00:40<00:39,  3.59it/s]\u001b[A\n",
      " 51%|█████▏    | 148/288 [00:41<00:39,  3.59it/s]\u001b[A\n",
      " 52%|█████▏    | 149/288 [00:41<00:38,  3.59it/s]\u001b[A\n",
      " 52%|█████▏    | 150/288 [00:41<00:38,  3.59it/s]\u001b[A\n",
      " 52%|█████▏    | 151/288 [00:42<00:38,  3.59it/s]\u001b[A\n",
      " 53%|█████▎    | 152/288 [00:42<00:37,  3.59it/s]\u001b[A\n",
      " 53%|█████▎    | 153/288 [00:42<00:37,  3.59it/s]\u001b[A\n",
      " 53%|█████▎    | 154/288 [00:43<00:38,  3.51it/s]\u001b[A\n",
      " 54%|█████▍    | 155/288 [00:44<00:37,  3.51it/s]\u001b[A\n",
      " 54%|█████▍    | 156/288 [00:44<00:37,  3.51it/s]\u001b[A\n",
      " 55%|█████▍    | 157/288 [00:44<00:37,  3.51it/s]\u001b[A\n",
      " 55%|█████▍    | 158/288 [00:45<00:37,  3.51it/s]\u001b[A\n",
      " 55%|█████▌    | 159/288 [00:45<00:36,  3.51it/s]\u001b[A\n",
      " 56%|█████▌    | 160/288 [00:45<00:36,  3.51it/s]\u001b[A\n",
      " 56%|█████▌    | 161/288 [00:45<00:36,  3.51it/s]\u001b[A\n",
      " 56%|█████▋    | 162/288 [00:46<00:35,  3.51it/s]\u001b[A\n",
      " 57%|█████▋    | 163/288 [00:46<00:35,  3.51it/s]\u001b[A\n",
      " 57%|█████▋    | 164/288 [00:46<00:35,  3.52it/s]\u001b[A\n",
      " 57%|█████▋    | 165/288 [00:46<00:34,  3.52it/s]\u001b[A\n",
      " 58%|█████▊    | 166/288 [00:47<00:34,  3.52it/s]\u001b[A\n",
      " 58%|█████▊    | 167/288 [00:47<00:34,  3.52it/s]\u001b[A\n",
      " 58%|█████▊    | 168/288 [00:47<00:34,  3.52it/s]\u001b[A\n",
      " 59%|█████▊    | 169/288 [00:47<00:33,  3.52it/s]\u001b[A\n",
      " 59%|█████▉    | 170/288 [00:48<00:33,  3.53it/s]\u001b[A\n",
      " 59%|█████▉    | 171/288 [00:48<00:33,  3.53it/s]\u001b[A\n",
      " 60%|█████▉    | 172/288 [00:48<00:32,  3.53it/s]\u001b[A\n",
      " 60%|██████    | 173/288 [00:49<00:32,  3.53it/s]\u001b[A\n",
      " 60%|██████    | 174/288 [00:49<00:32,  3.53it/s]\u001b[A\n",
      " 61%|██████    | 175/288 [00:49<00:31,  3.53it/s]\u001b[A\n",
      " 61%|██████    | 176/288 [00:49<00:31,  3.53it/s]\u001b[A\n",
      " 61%|██████▏   | 177/288 [00:50<00:31,  3.53it/s]\u001b[A\n",
      " 62%|██████▏   | 178/288 [00:50<00:31,  3.53it/s]\u001b[A\n",
      " 62%|██████▏   | 179/288 [00:50<00:30,  3.54it/s]\u001b[A\n",
      " 62%|██████▎   | 180/288 [00:50<00:30,  3.54it/s]\u001b[A\n",
      " 63%|██████▎   | 181/288 [00:51<00:30,  3.54it/s]\u001b[A\n",
      " 63%|██████▎   | 182/288 [00:51<00:29,  3.54it/s]\u001b[A\n",
      " 64%|██████▎   | 183/288 [00:51<00:29,  3.54it/s]\u001b[A\n",
      " 64%|██████▍   | 184/288 [00:51<00:29,  3.54it/s]\u001b[A\n",
      " 64%|██████▍   | 185/288 [00:52<00:29,  3.54it/s]\u001b[A\n",
      " 65%|██████▍   | 186/288 [00:52<00:28,  3.55it/s]\u001b[A\n",
      " 65%|██████▍   | 187/288 [00:52<00:28,  3.55it/s]\u001b[A\n",
      " 65%|██████▌   | 188/288 [00:52<00:28,  3.55it/s]\u001b[A\n",
      " 66%|██████▌   | 189/288 [00:53<00:27,  3.55it/s]\u001b[A\n",
      " 66%|██████▌   | 190/288 [00:53<00:27,  3.55it/s]\u001b[A\n",
      " 66%|██████▋   | 191/288 [00:53<00:27,  3.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************\n",
      "./chunked/train_*.bin ./chunked\\train_191.bin 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 192/288 [00:54<00:27,  3.55it/s]\u001b[A\n",
      " 67%|██████▋   | 193/288 [00:54<00:26,  3.55it/s]\u001b[A\n",
      " 67%|██████▋   | 194/288 [00:54<00:26,  3.55it/s]\u001b[A\n",
      " 68%|██████▊   | 195/288 [00:54<00:26,  3.55it/s]\u001b[A\n",
      " 68%|██████▊   | 196/288 [00:55<00:25,  3.55it/s]\u001b[A\n",
      " 68%|██████▊   | 197/288 [00:55<00:25,  3.56it/s]\u001b[A\n",
      " 69%|██████▉   | 198/288 [00:55<00:25,  3.56it/s]\u001b[A\n",
      " 69%|██████▉   | 199/288 [00:55<00:25,  3.56it/s]\u001b[A\n",
      " 69%|██████▉   | 200/288 [00:56<00:24,  3.56it/s]\u001b[A\n",
      " 70%|██████▉   | 201/288 [00:56<00:24,  3.56it/s]\u001b[A\n",
      " 70%|███████   | 202/288 [00:56<00:24,  3.56it/s]\u001b[A\n",
      " 70%|███████   | 203/288 [00:56<00:23,  3.56it/s]\u001b[A\n",
      " 71%|███████   | 204/288 [00:57<00:23,  3.56it/s]\u001b[A\n",
      " 71%|███████   | 205/288 [00:57<00:23,  3.56it/s]\u001b[A\n",
      " 72%|███████▏  | 206/288 [00:57<00:23,  3.57it/s]\u001b[A\n",
      " 72%|███████▏  | 207/288 [00:58<00:22,  3.57it/s]\u001b[A\n",
      " 72%|███████▏  | 208/288 [00:58<00:22,  3.57it/s]\u001b[A\n",
      " 73%|███████▎  | 209/288 [00:58<00:22,  3.57it/s]\u001b[A\n",
      " 73%|███████▎  | 210/288 [00:58<00:21,  3.57it/s]\u001b[A\n",
      " 73%|███████▎  | 211/288 [00:59<00:21,  3.57it/s]\u001b[A\n",
      " 74%|███████▎  | 212/288 [00:59<00:21,  3.57it/s]\u001b[A\n",
      " 74%|███████▍  | 213/288 [00:59<00:21,  3.57it/s]\u001b[A\n",
      " 74%|███████▍  | 214/288 [00:59<00:20,  3.57it/s]\u001b[A\n",
      " 75%|███████▍  | 215/288 [01:00<00:20,  3.57it/s]\u001b[A\n",
      " 75%|███████▌  | 216/288 [01:00<00:20,  3.57it/s]\u001b[A\n",
      " 75%|███████▌  | 217/288 [01:00<00:19,  3.57it/s]\u001b[A\n",
      " 76%|███████▌  | 218/288 [01:01<00:19,  3.57it/s]\u001b[A\n",
      " 76%|███████▌  | 219/288 [01:01<00:19,  3.57it/s]\u001b[A\n",
      " 76%|███████▋  | 220/288 [01:01<00:19,  3.57it/s]\u001b[A\n",
      " 77%|███████▋  | 221/288 [01:01<00:18,  3.58it/s]\u001b[A\n",
      " 77%|███████▋  | 222/288 [01:02<00:18,  3.58it/s]\u001b[A\n",
      " 77%|███████▋  | 223/288 [01:02<00:18,  3.58it/s]\u001b[A\n",
      " 78%|███████▊  | 224/288 [01:02<00:17,  3.58it/s]\u001b[A\n",
      " 78%|███████▊  | 225/288 [01:02<00:17,  3.58it/s]\u001b[A\n",
      " 78%|███████▊  | 226/288 [01:03<00:17,  3.58it/s]\u001b[A\n",
      " 79%|███████▉  | 227/288 [01:03<00:17,  3.58it/s]\u001b[A\n",
      " 79%|███████▉  | 228/288 [01:03<00:16,  3.58it/s]\u001b[A\n",
      " 80%|███████▉  | 229/288 [01:03<00:16,  3.58it/s]\u001b[A\n",
      " 80%|███████▉  | 230/288 [01:04<00:16,  3.58it/s]\u001b[A\n",
      " 80%|████████  | 231/288 [01:04<00:15,  3.58it/s]\u001b[A\n",
      " 81%|████████  | 232/288 [01:04<00:15,  3.58it/s]\u001b[A\n",
      " 81%|████████  | 233/288 [01:05<00:15,  3.58it/s]\u001b[A\n",
      " 81%|████████▏ | 234/288 [01:05<00:15,  3.58it/s]\u001b[A\n",
      " 82%|████████▏ | 235/288 [01:05<00:14,  3.58it/s]\u001b[A\n",
      " 82%|████████▏ | 236/288 [01:05<00:14,  3.58it/s]\u001b[A\n",
      " 82%|████████▏ | 237/288 [01:06<00:14,  3.58it/s]\u001b[A\n",
      " 83%|████████▎ | 238/288 [01:06<00:13,  3.58it/s]\u001b[A\n",
      " 83%|████████▎ | 239/288 [01:06<00:13,  3.58it/s]\u001b[A\n",
      " 83%|████████▎ | 240/288 [01:07<00:13,  3.58it/s]\u001b[A\n",
      " 84%|████████▎ | 241/288 [01:07<00:13,  3.58it/s]\u001b[A\n",
      " 84%|████████▍ | 242/288 [01:07<00:12,  3.58it/s]\u001b[A\n",
      " 84%|████████▍ | 243/288 [01:07<00:12,  3.58it/s]\u001b[A\n",
      " 85%|████████▍ | 244/288 [01:08<00:12,  3.58it/s]\u001b[A\n",
      " 85%|████████▌ | 245/288 [01:08<00:12,  3.58it/s]\u001b[A\n",
      " 85%|████████▌ | 246/288 [01:08<00:11,  3.58it/s]\u001b[A\n",
      " 86%|████████▌ | 247/288 [01:08<00:11,  3.58it/s]\u001b[A\n",
      " 86%|████████▌ | 248/288 [01:09<00:11,  3.58it/s]\u001b[A\n",
      " 86%|████████▋ | 249/288 [01:09<00:10,  3.58it/s]\u001b[A\n",
      " 87%|████████▋ | 250/288 [01:09<00:10,  3.58it/s]\u001b[A\n",
      " 87%|████████▋ | 251/288 [01:10<00:10,  3.58it/s]\u001b[A\n",
      " 88%|████████▊ | 252/288 [01:10<00:10,  3.58it/s]\u001b[A\n",
      " 88%|████████▊ | 253/288 [01:10<00:09,  3.58it/s]\u001b[A\n",
      " 88%|████████▊ | 254/288 [01:10<00:09,  3.58it/s]\u001b[A\n",
      " 89%|████████▊ | 255/288 [01:12<00:09,  3.50it/s]\u001b[A\n",
      " 89%|████████▉ | 256/288 [01:13<00:09,  3.50it/s]\u001b[A\n",
      " 89%|████████▉ | 257/288 [01:13<00:08,  3.50it/s]\u001b[A\n",
      " 90%|████████▉ | 258/288 [01:13<00:08,  3.50it/s]\u001b[A\n",
      " 90%|████████▉ | 259/288 [01:14<00:08,  3.50it/s]\u001b[A\n",
      " 90%|█████████ | 260/288 [01:14<00:08,  3.50it/s]\u001b[A\n",
      " 91%|█████████ | 261/288 [01:14<00:07,  3.50it/s]\u001b[A\n",
      " 91%|█████████ | 262/288 [01:14<00:07,  3.50it/s]\u001b[A\n",
      " 91%|█████████▏| 263/288 [01:15<00:07,  3.50it/s]\u001b[A\n",
      " 92%|█████████▏| 264/288 [01:15<00:06,  3.50it/s]\u001b[A\n",
      " 92%|█████████▏| 265/288 [01:15<00:06,  3.50it/s]\u001b[A\n",
      " 92%|█████████▏| 266/288 [01:16<00:06,  3.50it/s]\u001b[A\n",
      " 93%|█████████▎| 267/288 [01:16<00:06,  3.50it/s]\u001b[A\n",
      " 93%|█████████▎| 268/288 [01:16<00:05,  3.50it/s]\u001b[A\n",
      " 93%|█████████▎| 269/288 [01:16<00:05,  3.50it/s]\u001b[A\n",
      " 94%|█████████▍| 270/288 [01:17<00:05,  3.50it/s]\u001b[A\n",
      " 94%|█████████▍| 271/288 [01:17<00:04,  3.50it/s]\u001b[A\n",
      " 94%|█████████▍| 272/288 [01:17<00:04,  3.50it/s]\u001b[A\n",
      " 95%|█████████▍| 273/288 [01:17<00:04,  3.50it/s]\u001b[A\n",
      " 95%|█████████▌| 274/288 [01:18<00:03,  3.50it/s]\u001b[A\n",
      " 95%|█████████▌| 275/288 [01:18<00:03,  3.50it/s]\u001b[A\n",
      " 96%|█████████▌| 276/288 [01:18<00:03,  3.50it/s]\u001b[A\n",
      " 96%|█████████▌| 277/288 [01:19<00:03,  3.50it/s]\u001b[A\n",
      " 97%|█████████▋| 278/288 [01:19<00:02,  3.50it/s]\u001b[A\n",
      " 97%|█████████▋| 279/288 [01:19<00:02,  3.50it/s]\u001b[A\n",
      " 97%|█████████▋| 280/288 [01:19<00:02,  3.50it/s]\u001b[A\n",
      " 98%|█████████▊| 281/288 [01:20<00:01,  3.50it/s]\u001b[A\n",
      " 98%|█████████▊| 282/288 [01:20<00:01,  3.50it/s]\u001b[A\n",
      " 98%|█████████▊| 283/288 [01:20<00:01,  3.50it/s]\u001b[A\n",
      " 99%|█████████▊| 284/288 [01:21<00:01,  3.50it/s]\u001b[A\n",
      " 99%|█████████▉| 285/288 [01:21<00:00,  3.51it/s]\u001b[A\n",
      " 99%|█████████▉| 286/288 [01:21<00:00,  3.51it/s]\u001b[A\n",
      "100%|█████████▉| 287/288 [01:21<00:00,  3.51it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [01:21<02:43, 81.94s/it]t/s]\u001b[A\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "287112\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 1/14 [00:00<00:03,  3.65it/s]\u001b[A\n",
      " 14%|█▍        | 2/14 [00:00<00:03,  3.67it/s]\u001b[A\n",
      " 21%|██▏       | 3/14 [00:00<00:02,  3.77it/s]\u001b[A\n",
      " 29%|██▊       | 4/14 [00:01<00:02,  3.79it/s]\u001b[A\n",
      " 36%|███▌      | 5/14 [00:01<00:02,  3.80it/s]\u001b[A\n",
      " 43%|████▎     | 6/14 [00:01<00:02,  3.78it/s]\u001b[A\n",
      " 50%|█████     | 7/14 [00:01<00:01,  3.72it/s]\u001b[A\n",
      " 57%|█████▋    | 8/14 [00:02<00:01,  3.65it/s]\u001b[A\n",
      " 64%|██████▍   | 9/14 [00:02<00:01,  3.65it/s]\u001b[A\n",
      " 71%|███████▏  | 10/14 [00:02<00:01,  3.64it/s]\u001b[A\n",
      " 79%|███████▊  | 11/14 [00:03<00:00,  3.63it/s]\u001b[A\n",
      " 86%|████████▌ | 12/14 [00:03<00:00,  3.63it/s]\u001b[A\n",
      " 93%|█████████▎| 13/14 [00:03<00:00,  3.63it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [01:25<00:42, 42.81s/it]s]\u001b[A\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "13368\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 1/12 [00:00<00:02,  3.73it/s]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:00<00:02,  3.73it/s]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:00<00:02,  3.79it/s]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:01<00:02,  3.82it/s]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:01<00:01,  3.76it/s]\u001b[A\n",
      " 50%|█████     | 6/12 [00:01<00:01,  3.74it/s]\u001b[A\n",
      " 58%|█████▊    | 7/12 [00:01<00:01,  3.73it/s]\u001b[A\n",
      " 67%|██████▋   | 8/12 [00:02<00:01,  3.69it/s]\u001b[A\n",
      " 75%|███████▌  | 9/12 [00:02<00:00,  3.69it/s]\u001b[A\n",
      " 83%|████████▎ | 10/12 [00:02<00:00,  3.68it/s]\u001b[A\n",
      " 92%|█████████▏| 11/12 [00:03<00:00,  3.66it/s]\u001b[A\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.80it/s]\u001b[A\n",
      "100%|██████████| 3/3 [01:28<00:00, 29.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "11490\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_decoding = vocab.word2id(START_DECODING)\n",
    "stop_decoding = vocab.word2id(STOP_DECODING)\n",
    "\n",
    "input_index=[]\n",
    "dec_inputs_index=[]\n",
    "target_index=[]\n",
    "inputs_len=[]\n",
    "dec_inputs_len=[]\n",
    "\n",
    "index_data = {}\n",
    "\n",
    "zero_len = 0\n",
    "\n",
    "dec_max_len = 20\n",
    "enc_max_len = 200\n",
    "\n",
    "pad_id = vocab.word2id(PAD_TOKEN)\n",
    "files_group = list(stories.keys())\n",
    "\n",
    "for file_group in tqdm.tqdm(files_group):\n",
    "    for file in tqdm.tqdm(list(stories[file_group].keys())):       \n",
    "        for data in list(stories[file_group][file].keys()):\n",
    "            if stories[file_group][file][data]['abstract_sentences'] == []:\n",
    "                print('*********************************************')\n",
    "                abstract = stories[file_group][file][data]['abstract']\n",
    "                abstract_sentences = []\n",
    "                article = stories[file_group][file][data]['article']\n",
    "                example=Example(article=article,abstract_sentences=abstract_sentences,vocab=vocab)\n",
    "                example.pad_decoder_inp_targ(dec_max_len,pad_id)\n",
    "                example.pad_encoder_input(enc_max_len,pad_id)\n",
    "            else:\n",
    "                abstract = stories[file_group][file][data]['abstract']\n",
    "                abstract_sentences = [stories[file_group][file][data]['abstract_sentences'][0]]\n",
    "                article = stories[file_group][file][data]['article']\n",
    "                example=Example(article=article,abstract_sentences=abstract_sentences,vocab=vocab)\n",
    "                example.pad_decoder_inp_targ(dec_max_len,pad_id)\n",
    "                example.pad_encoder_input(enc_max_len,pad_id)\n",
    "            if example.enc_len <= 0 or example.dec_len <= 0:\n",
    "                print(file_group, file, data)\n",
    "                zero_len +=1\n",
    "                pass\n",
    "            else:\n",
    "                input_index.append(example.enc_input)\n",
    "                dec_inputs_index.append(example.dec_input)\n",
    "                target_index.append(example.target)\n",
    "                inputs_len.append(example.enc_len)\n",
    "                dec_inputs_len.append(example.dec_len)\n",
    "    print('********************************************************************************')\n",
    "    print(len(input_index))\n",
    "    print('********************************************************************************')\n",
    "    index_data[file_group] = (input_index,inputs_len,dec_inputs_index,dec_inputs_len,target_index)\n",
    "    input_index=[]\n",
    "    dec_inputs_index=[]\n",
    "    target_index=[]\n",
    "    inputs_len=[]\n",
    "    dec_inputs_len=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./chunked/train_*.bin\n",
      "287112\n",
      "28711\n",
      "./chunked/val_*.bin\n",
      "13368\n",
      "1336\n",
      "./chunked/test_*.bin\n",
      "11490\n",
      "1148\n"
     ]
    }
   ],
   "source": [
    "for file_group in files_group:\n",
    "    print(file_group)\n",
    "    (input_index,inputs_len,dec_inputs_index,dec_inputs_len,target_index) = index_data[file_group]\n",
    "    print(len(input_index))\n",
    "    start = int(len(input_index)*0.7)\n",
    "    end = -1\n",
    "    index_data[file_group] = (input_index[start:end],inputs_len[start:end],dec_inputs_index[start:end],dec_inputs_len[start:end],target_index[start:end])\n",
    "    (input_index,inputs_len,dec_inputs_index,dec_inputs_len,target_index) = index_data[file_group]\n",
    "    print(len(input_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 300\n",
    "hidden_size = 150\n",
    "word_dropout = 0.5\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "batch_size_fit = 1024-256\n",
    "rnn_type = 'gru'\n",
    "learning_rate = 0.001\n",
    "\n",
    "vocab_size = len(vocab._word_to_id)\n",
    "\n",
    "# <s> and </s> are used in the data files to segment the abstracts into sentences. They don't receive vocab ids.\n",
    "SENTENCE_START = '<s>'\n",
    "SENTENCE_END = '</s>'\n",
    "\n",
    "PAD_TOKEN = '[PAD]' # This has a vocab id, which is used to pad the encoder input, decoder input and target sequence\n",
    "UNKNOWN_TOKEN = '[UNK]' # This has a vocab id, which is used to represent out-of-vocabulary words\n",
    "START_DECODING = '[START]' # This has a vocab id, which is used at the start of every decoder input sequence\n",
    "STOP_DECODING = '[STOP]' # This has a vocab id, which is used at the end of untruncated target sequences\n",
    "\n",
    "# Note: none of <s>, </s>, [PAD], [UNK], [START], [STOP] should appear in the vocab file.\n",
    "\n",
    "sos_idx = vocab.word2id(START_DECODING)\n",
    "eos_idx = vocab.word2id(STOP_DECODING)\n",
    "pad_idx = vocab.word2id(PAD_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding_layer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, numpy_embedding = None):\n",
    "        super().__init__()\n",
    "#         if numpy_embedding == None:\n",
    "#             self.embedding = nn.Embedding(vocab_size,embedding_size)\n",
    "#         else:\n",
    "        self.model_embedding = torch.from_numpy(numpy_embedding).float()\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_size)\n",
    "        self.embedding.weight = nn.Parameter(self.model_embedding)\n",
    "            \n",
    "    def forward(self,inputs):\n",
    "        return self.embedding(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq_encoder(nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_size, hidden_size, word_dropout,\n",
    "                 sos_idx, eos_idx, pad_idx, embedding,rnn_type='rnn' , num_layers=1, bidirectional=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        #self.model_embedding = torch.from_numpy(numpy_embedding)\n",
    "        self.sos_idx = sos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.pad_idx = pad_idx\n",
    "        self.vocab_size = vocab_size\n",
    "        self.rnn_type = rnn_type\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        #self.embedding.weight = nn.Parameter(self.model_embedding)\n",
    "        \n",
    "        self.encoder = encoder(vocab_size = self.vocab_size, embedding_size = embedding_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional = bidirectional,rnn_type = rnn_type).cuda()\n",
    "        #self.decoder = Decoder(vocab_size = vocab_size,embedding_size = embedding_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional = False,rnn_type = rnn_type, word_dropout=word_dropout).cuda()\n",
    "        \n",
    "    def forward(self,x,length,y_): \n",
    "        #print(x.size())\n",
    "        batch_size = x.size(0)\n",
    "        sorted_lengths, sorted_idx = torch.sort(length, descending=True)\n",
    "        input_sequence = x[sorted_idx.cuda()]\n",
    "        input_embedding = self.embedding(input_sequence).float()\n",
    "\n",
    "        packed_input = rnn_utils.pack_padded_sequence(input_embedding, sorted_lengths.tolist(), batch_first=True)\n",
    "\n",
    "        self.encoder_outputs, self.encoder_hidden_state, self.encoder_hidden_state_attn = self.encoder(packed_input,batch_size)\n",
    "\n",
    "        padded_outputs = rnn_utils.pad_packed_sequence(self.encoder_outputs, batch_first=True)[0]\n",
    "        padded_outputs = padded_outputs.contiguous()\n",
    "        _,reversed_idx = torch.sort(sorted_idx.cuda())\n",
    "        self.encoder_outputs = padded_outputs[reversed_idx]        \n",
    "        \n",
    "        return self.encoder_outputs, self.encoder_hidden_state, self.encoder_hidden_state_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size, hidden_size, bidirectional=True, num_layers = 1,rnn_type='rnn'):\n",
    "        super(encoder,self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.rnn_type = rnn_type\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.rnn_type == 'rnn':\n",
    "            rnn = nn.RNN\n",
    "        elif self.rnn_type == 'gru':\n",
    "            rnn = nn.GRU\n",
    "        elif self.rnn_type =='lstm':\n",
    "            rnn = nn.LSTM\n",
    "        else:\n",
    "            raise ValueError()\n",
    "            \n",
    "        \n",
    "        self.encoder = rnn(self.embedding_size, self.hidden_size, num_layers = self.num_layers, bidirectional = self.bidirectional, batch_first = True)\n",
    "        self.encoder.weight_hh_l0 = nn.init.xavier_uniform(self.encoder.weight_hh_l0)\n",
    "        self.encoder.weight_ih_l0 = nn.init.xavier_uniform(self.encoder.weight_ih_l0)\n",
    "\n",
    "        self.hidden_factor = (2 if self.bidirectional else 1) * self.num_layers\n",
    "\n",
    "    \n",
    "    def forward(self,x,batch_size):\n",
    "        \n",
    "        outputs, self.hidden = self.encoder(x)\n",
    "        \n",
    "        if self.bidirectional or self.num_layers > 1:\n",
    "            # flatten hidden state\n",
    "            self.hidden_ = self.hidden.view(batch_size, self.hidden_size*self.hidden_factor)\n",
    "        else:\n",
    "            self.hidden_ = self.hidden.squeeze()\n",
    "\n",
    "        \n",
    "        return outputs, self.hidden_, self.hidden[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size, max_length=20):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        \n",
    "         # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(batch_size,seq_len)).cuda()# B x 1 x S\n",
    "        \n",
    "\n",
    "        # Calculate energies for each encoder output\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[:,i] = self.score(hidden, encoder_outputs[:,i]).squeeze()\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.bmm(energy.unsqueeze(2))\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.other.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq_decoder(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size , hidden_size, encoder_bi, embedding, bidirectional=True, num_layers = 1,rnn_type='rnn',word_dropout = 0.5):\n",
    "        super(Seq2Seq_decoder,self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.rnn_type = rnn_type\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = Attn('general', hidden_size)\n",
    "        self.encoder_bi = encoder_bi\n",
    "        if self.rnn_type == 'rnn':\n",
    "            rnn = nn.RNN\n",
    "        elif self.rnn_type == 'gru':\n",
    "            rnn = nn.GRU\n",
    "        elif self.rnn_type =='lstm':\n",
    "            rnn = nn.LSTM\n",
    "        else:\n",
    "            raise ValueError()\n",
    "            \n",
    "        self.hidden_factor = (2 if self.encoder_bi else 1)           \n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.word_dropout = nn.Dropout(p=word_dropout)\n",
    "        \n",
    "        self.decoder = rnn(embedding_size+hidden_size, hidden_size, num_layers=num_layers, bidirectional=self.bidirectional, batch_first=True)\n",
    "        self.decoder.weight_hh_l0 = nn.init.xavier_uniform(self.decoder.weight_hh_l0)\n",
    "        self.decoder.weight_ih_l0 = nn.init.xavier_uniform(self.decoder.weight_ih_l0)\n",
    "        \n",
    "        self.hidden2hidden = nn.Linear(hidden_size * 2*(2 if bidirectional else 1), hidden_size)\n",
    "        self.hidden2outputs = nn.Linear(hidden_size, hidden_size)\n",
    "        self.outputs2vocab = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        \n",
    "    def forward(self,batch_size,context,hidden,encoder_outputs):\n",
    "        self.batch_size = batch_size.size(0)\n",
    "        self.context = context\n",
    "\n",
    "        if  self.num_layers > 1:\n",
    "            # unflatten hidden state\n",
    "            self.hidden = hidden.view(self.hidden_factor, self.batch_size, self.hidden_size)\n",
    "        else:\n",
    "            #hidden = hidden[-1]\n",
    "            self.hidden = hidden.unsqueeze(0)\n",
    "        #print(hidden.size())    \n",
    "        self.input_embedding = self.embedding(batch_size).view(encoder_outputs.size(0),1, -1)\n",
    "\n",
    "        self.inputs = torch.cat((self.input_embedding, self.context), 2)\n",
    "        self.dec_outputs,self.hidden = self.decoder(self.inputs, self.hidden)\n",
    "        \n",
    "        \n",
    "        self.attn_weights = self.attn(self.dec_outputs, encoder_outputs)\n",
    "        self.context = self.attn_weights.bmm(encoder_outputs)\n",
    "        \n",
    "        self.attn2output = torch.cat((self.dec_outputs.squeeze(),context.squeeze()),1)\n",
    "        \n",
    "        #self.test = self.dec_outputs + self.context\n",
    "        self.outputs = nn.functional.log_softmax(self.outputs2vocab(self.hidden2outputs(self.hidden2hidden(self.attn2output)+self.input_embedding.squeeze())))\n",
    "        #self.outputs = nn.functional.log_softmax(self.outputs2vocab(self.outputs.squeeze()))\n",
    "        \n",
    "        return self.outputs, self.context, self.hidden, self.attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding_layer(vocab_size, embedding_size,numpy_embedding = model_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder=Seq2Seq_encoder(vocab_size, embedding_size, hidden_size, word_dropout,sos_idx, eos_idx, pad_idx , num_layers=num_layers ,rnn_type='gru',bidirectional= bidirectional,embedding =embedding ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decoder = Seq2Seq_decoder(vocab_size = vocab_size,embedding_size = embedding_size, hidden_size = hidden_size*2, num_layers = num_layers, encoder_bi= bidirectional,bidirectional = False,rnn_type = rnn_type, word_dropout=word_dropout,embedding =embedding).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder,Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLL = torch.nn.NLLLoss(ignore_index = pad_idx)\n",
    "\n",
    "optimizer_encoder = torch.optim.Adam(Encoder.parameters(), lr=learning_rate)\n",
    "optimizer_decoder = torch.optim.Adam(Decoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def batch(batch_size,input_var,dec_input_var,target_var,length_var, dec_length_var):\n",
    "\n",
    "    shuffle_list = list(zip(input_var,dec_input_var,target_var,length_var,dec_length_var))\n",
    "    random.shuffle(shuffle_list)\n",
    "    \n",
    "    start = 0\n",
    "    end = batch_size\n",
    "    #if len(input_var)%32 != 0:\n",
    "    while end < len(input_var):\n",
    "        batch_input = []\n",
    "        batch_input_dec = []\n",
    "        batch_target = []\n",
    "        batch_length = []\n",
    "        batch_length_dec = []\n",
    "        \n",
    "        batch_shuffle = shuffle_list[start:end]\n",
    "        \n",
    "        for i,j,k,n,m in batch_shuffle:\n",
    "            batch_input.append(i)\n",
    "            batch_input_dec.append(j)\n",
    "            batch_target.append(k)\n",
    "            batch_length.append(n)\n",
    "            batch_length_dec.append(m)\n",
    "            \n",
    "        temp = end\n",
    "        end  = end + batch_size\n",
    "        start = temp\n",
    "        yield batch_input, batch_input_dec, batch_target, batch_length, batch_length_dec\n",
    "        \n",
    "    if end >= len(input_var):\n",
    "        batch_input = []\n",
    "        batch_input_dec = []\n",
    "        batch_target = []\n",
    "        batch_length = []\n",
    "        batch_length_dec = []\n",
    "        batch_shuffle = shuffle_list[start:]\n",
    "        \n",
    "        for i,j,k,n,m in batch_shuffle:\n",
    "            batch_input.append(i)\n",
    "            batch_input_dec.append(j)\n",
    "            batch_target.append(k)\n",
    "            batch_length.append(n)\n",
    "            batch_length_dec.append(m)\n",
    "        yield batch_input, batch_input_dec, batch_target, batch_length, batch_length_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "max_target_len = 20\n",
    "clip = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['./chunked/train_*.bin', './chunked/val_*.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step = 0\n",
    "var_losses = []\n",
    "train_losses = []\n",
    "avg_losses = []\n",
    "\n",
    "iteration = 0\n",
    "for epoch in tqdm.tqdm(range(epochs+1)):\n",
    "    \n",
    "    for path in paths :\n",
    "        print(path)\n",
    "        input_index, inputs_len, dec_inputs_index, dec_inputs_len, target_index = index_data[path]\n",
    "        \n",
    "        for batch_x, batch_y_x, batch_y, batch_len, batch_len_y in batch(batch_size_fit, input_index, \\\n",
    "                                                                         dec_inputs_index,target_index, \\\n",
    "                                                                         inputs_len, dec_inputs_len):\n",
    "            optimizer_encoder.zero_grad()\n",
    "            optimizer_decoder.zero_grad()\n",
    "\n",
    "            iteration = iteration + 1\n",
    "\n",
    "            if path == paths[0]:\n",
    "                Encoder.train()\n",
    "                Decoder.train()\n",
    "            else:\n",
    "                Encoder.eval()\n",
    "                Decoder.eval()\n",
    "\n",
    "            x_ = Variable(torch.cuda.LongTensor(batch_x))\n",
    "            y_ = Variable(torch.cuda.LongTensor(batch_y)).transpose(1,0)\n",
    "            batch_size = x_.size(0)\n",
    "\n",
    "            length = torch.cuda.LongTensor(batch_len)\n",
    "\n",
    "            decoder_input=Variable(torch.cuda.LongTensor(batch_size)).fill_(sos_idx)\n",
    "\n",
    "            encoder_outputs, encoder_hidden_state,encoder_hidden_state_attn = Encoder(x_,length,y_)\n",
    "            decoder_context = Variable(torch.zeros(batch_size,1, Decoder.hidden_size)).cuda()\n",
    "            decoder_hidden = encoder_hidden_state\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            for i in range(max_target_len):\n",
    "                decoder_output, decoder_context, decoder_hidden, decoder_attention = Decoder(decoder_input,decoder_context,decoder_hidden,encoder_outputs)\n",
    "\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "\n",
    "                loss += NLL(decoder_output,y_[i])\n",
    "                decoder_hidden = decoder_hidden.squeeze(0)\n",
    "                decoder_input = y_[i]\n",
    "\n",
    "            \n",
    "            if path == paths[0]:\n",
    "\n",
    "                loss.backward()\n",
    "                #torch.nn.utils.clip_grad_norm(Encoder.parameters(), clip)\n",
    "                #torch.nn.utils.clip_grad_norm(Decoder.parameters(), clip)\n",
    "                optimizer_encoder.step()\n",
    "                optimizer_decoder.step()\n",
    "\n",
    "                loss = loss.data[0]/max_target_len\n",
    "\n",
    "                train_losses.append(loss)\n",
    "\n",
    "                step += 1\n",
    "\n",
    "                if iteration % 10 == 0 or iteration == (len(input_index)-1)//batch_size:\n",
    "                    print(\"Batch %04d/%i, Loss %9.4f\"%( iteration, (len(input_index)-1)//batch_size_fit, loss))\n",
    "                    np.savez(L=train_losses,file='./train_loss.npz')\n",
    "                    checkpoint_path_encoder = os.path.join(save_model_path, \"enc_E%i.pytorch\"%(epoch))\n",
    "                    checkpoint_path_decoder = os.path.join(save_model_path, \"dec_E%i.pytorch\"%(epoch))\n",
    "                    torch.save(Encoder, checkpoint_path_encoder)\n",
    "                    torch.save(Decoder, checkpoint_path_decoder)\n",
    "\n",
    "            else:\n",
    "\n",
    "                loss = loss.data[0]/max_target_len\n",
    "\n",
    "                var_losses.append(loss)\n",
    "\n",
    "                step += 1\n",
    "\n",
    "                if iteration % 10 == 0 or iteration == (len(input_index)-1)//batch_size:\n",
    "                    print(\"Valid Batch %04d/%i, Loss %9.4f\"%( iteration, (len(input_index)-1)//batch_size_fit, loss))\n",
    "                    np.savez(L=var_losses,file='./var_loss.npz')\n",
    "\n",
    "            del loss\n",
    "            del encoder_outputs\n",
    "            del encoder_hidden_state \n",
    "        iteration = 0\n",
    "    print(\"Model saved at %s\"%save_model_path)\n",
    "    print(\"Epoch %02d/%i, Mean ELBO %9.4f\"%( epoch, epochs, np.mean(np.array(var_losses))))\n",
    "    avg_losses.append(np.mean(np.array(var_losses)))\n",
    "    np.savez(L=avg_losses,file='./avg_losses.npz')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path,epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = os.path.join('won', '2018-Jul-30-00-58-21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_encoder = os.path.join(save_model_path, 'enc_E8.pytorch')\n",
    "checkpoint_path_decoder = os.path.join(save_model_path, 'dec_E8.pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = torch.load(checkpoint_path_encoder)\n",
    "Decoder = torch.load(checkpoint_path_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder.eval()\n",
    "Decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder,Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_index,inputs_len,dec_inputs_index,dec_inputs_len,target_index) = index_data[files_group[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#del x_\n",
    "#del Y_X\n",
    "del Encoder\n",
    "del Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_len = []\n",
    "for sentence in input_index[start:end]:\n",
    "    inputs_len.append(len(sentence) - sentence.count(0))\n",
    "dec_inputs_len = []\n",
    "for sentence in dec_inputs_index[start:end]:\n",
    "    dec_inputs_len.append(len(sentence) - sentence.count(vocab.word2id(PAD_TOKEN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = Variable(torch.cuda.LongTensor(input_index[start:end]))\n",
    "Y_X = Variable(torch.cuda.LongTensor(dec_inputs_index[start:end]))\n",
    "\n",
    "batch_size = x_.size(0)\n",
    "length = torch.cuda.LongTensor(inputs_len)\n",
    "length_y = torch.cuda.LongTensor(dec_inputs_len)\n",
    "\n",
    "sorted_lengths, sorted_idx = torch.sort(length, descending=True)\n",
    "input_sequence = x_[sorted_idx.cuda()]\n",
    "input_embedding = Encoder.embedding(input_sequence)\n",
    "_,reversed_idx = torch.sort(sorted_idx.cuda())\n",
    "packed_input = rnn_utils.pack_padded_sequence(input_embedding, sorted_lengths.tolist(), batch_first=True)\n",
    "\n",
    "encoder_outputs, encoder_hidden_state,encoder_hidden_state_attn = Encoder.encoder(packed_input,batch_size)\n",
    "\n",
    "padded_outputs = rnn_utils.pad_packed_sequence(encoder_outputs, batch_first=True)[0]\n",
    "padded_outputs = padded_outputs.contiguous()\n",
    "_,reversed_idx = torch.sort(sorted_idx.cuda())\n",
    "encoder_outputs = padded_outputs[reversed_idx]\n",
    "\n",
    "decoder_input=Variable(torch.cuda.LongTensor(encoder_outputs.size(0))).fill_(sos_idx)\n",
    "\n",
    "Y = Variable(torch.cuda.LongTensor(target_index[start:end])).transpose(1,0)\n",
    "\n",
    "if len(encoder_hidden_state.size()) == 1:\n",
    "    decoder_hidden = encoder_hidden_state.unsqueeze(0)\n",
    "else: \n",
    "    decoder_hidden = encoder_hidden_state\n",
    "decoder_context = Variable(torch.zeros(batch_size,1, Decoder.hidden_size)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_words = []\n",
    "decoder_attentions = torch.zeros(encoder_outputs.size(0),dec_max_len, enc_max_len)\n",
    "for i in range(dec_max_len):\n",
    "\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = Decoder(decoder_input,decoder_context,decoder_hidden.float(),encoder_outputs.float())\n",
    "\n",
    "    decoder_attentions[:decoder_attention.size(0),i,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "    topv, topi = decoder_output.data.topk(1)\n",
    "\n",
    "    temp = []\n",
    "    if len(topi.size()) == 1:\n",
    "        temp.append(vocab.id2word(topi.cpu().numpy()[0]))\n",
    "    else:\n",
    "        for top in topi.cpu().numpy():\n",
    "            temp.append(vocab.id2word(top[0]))\n",
    "    decoded_words.append(temp)\n",
    "    decoder_input = Variable(topi).cuda()\n",
    "    decoder_hidden = decoder_hidden.squeeze()\n",
    "    if len(decoder_hidden.size()) == 1:\n",
    "        decoder_hidden = decoder_hidden.unsqueeze(0)\n",
    "    else: \n",
    "        decoder_hidden = decoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferences = []\n",
    "for decoded_sent in np.array(decoded_words).transpose():\n",
    "    for i,word in enumerate(decoded_sent):\n",
    "        if word == STOP_DECODING:\n",
    "            decoded_sent = decoded_sent[:i]\n",
    "\n",
    "    inferences.append(list(decoded_sent))\n",
    "\n",
    "\n",
    "targets_result = []\n",
    "for inputs in target_index[start:end]:\n",
    "    result = []\n",
    "    for word in inputs:\n",
    "        if word == eos_idx:\n",
    "            break\n",
    "        else:\n",
    "            result.append(vocab.id2word(word))\n",
    "    targets_result.append(result)    \n",
    "\n",
    "inputs_result = []\n",
    "for inputs in input_index[start:end]:\n",
    "    result = []\n",
    "    for word in inputs:\n",
    "        result.append(vocab.id2word(word))\n",
    "    inputs_result.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for source,target,inference, decoder_attention in zip(inputs_result, targets_result, inferences, decoder_attentions):\n",
    "    print('*********************************************************************')\n",
    "    print('source : '+' '.join(source))\n",
    "    \n",
    "    print('*********************************************************************')\n",
    "    print('target : '+' '.join(target))\n",
    "    \n",
    "    print('*********************************************************************')\n",
    "    print('inference : '+' '.join(inference))\n",
    "    \n",
    "    print('*********************************************************************')\n",
    "    scores = rouge.get_scores(' '.join(target), ' '.join(inference))\n",
    "    for score in scores[0]:\n",
    "        print(score +' : '+str(scores[0][score]))\n",
    "\n",
    "    plt.matshow(decoder_attention.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_recall = []\n",
    "r2_recall = []\n",
    "rl_recall = []\n",
    "\n",
    "r1_f1 = []\n",
    "r2_f1 = []\n",
    "rl_f1 = []\n",
    "\n",
    "error = 0\n",
    "\n",
    "for source,target,inference, decoder_attention in tqdm.tqdm(zip(inputs_result, targets_result, inferences, decoder_attentions)):\n",
    "    try:\n",
    "        scores = rouge.get_scores(' '.join(target), ' '.join(inference))\n",
    "    except ValueError:\n",
    "        error +=1\n",
    "        print('******************************************')\n",
    "        print('target'+' '.join(target))\n",
    "        print('inference'+' '.join(inference))\n",
    "        pass\n",
    "    r1_recall.append(scores[0]['rouge-1']['r'])\n",
    "    r2_recall.append(scores[0]['rouge-2']['r'])\n",
    "    rl_recall.append(scores[0]['rouge-l']['r'])\n",
    "    \n",
    "    r1_f1.append(scores[0]['rouge-1']['f'])\n",
    "    r2_f1.append(scores[0]['rouge-2']['f'])\n",
    "    rl_f1.append(scores[0]['rouge-l']['f'])\n",
    "print('error sentence : ' + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROUGE-1 recall : ' + str(sum(r1_recall)*100 / len(r1_recall)))\n",
    "print('ROUGE-1 F1 : ' + str(sum(r1_f1)*100 / len(r1_f1)))\n",
    "print('********************************************************************')\n",
    "print('ROUGE-2 recall : ' + str(sum(r2_recall)*100 / len(r2_recall)))\n",
    "print('ROUGE-2 F1 : ' + str(sum(r2_f1)*100 / len(r2_f1)))\n",
    "print('********************************************************************')\n",
    "print('ROUGE-l recall : ' + str(sum(rl_recall)*100 / len(rl_recall)))\n",
    "print('ROUGE-l F1 : ' + str(sum(rl_f1)*100 / len(rl_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input length: 200, Output length: 20\n",
    "## Encoder: bi_layer1, Decoder: layer1, Ouput: 3layer, hidden: 200\n",
    "********************************************************************\n",
    "ROUGE-1 recall : 18.32848421558105  \n",
    "ROUGE-1 F1 : 14.55207536225354\n",
    "********************************************************************\n",
    "ROUGE-2 recall : 2.12192578890871  \n",
    "ROUGE-2 F1 : 1.929616342515873\n",
    "********************************************************************\n",
    "ROUGE-l recall : 16.305944007556953  \n",
    "ROUGE-l F1 : 11.950990121991415\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## '2018-Jul-19-03-00-40' Epoch: 6\n",
    "## Input length: 200, Output length: 20\n",
    "## Encoder: bi_layer2, Decoder: layer2, Ouput: 3layer, hidden: 200\n",
    "********************************************************************\n",
    "ROUGE-1 recall : 21.747208037530445  \n",
    "ROUGE-1 F1 : 14.735247486910408\n",
    "********************************************************************\n",
    "ROUGE-2 recall : 2.826018309889277  \n",
    "ROUGE-2 F1 : 2.0510893369941567\n",
    "********************************************************************\n",
    "ROUGE-l recall : 20.20920690275513  \n",
    "ROUGE-l F1 : 11.742692338164279\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
